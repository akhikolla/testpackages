<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Lampros Mouselimis" />

<meta name="date" content="2019-11-29" />

<title>Regression using the Housing data</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Regression using the Housing data</h1>
<h4 class="author">Lampros Mouselimis</h4>
<h4 class="date">2019-11-29</h4>



<p>The following examples illustrate the functionality of the KernelKnn package for <strong>regression</strong> tasks. I’ll make use of the <em>Housing</em> data set,</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">data</span>(Boston, <span class="dt">package =</span> <span class="st">'KernelKnn'</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">str</span>(Boston)</a></code></pre></div>
<pre><code>## 'data.frame':    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ black  : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<p><br></p>
<p>When using an algorithm where the ouput depends on distance calculation (as is the case in k-nearest-neighbors) it is recommended to first scale the data,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">X =<span class="st"> </span><span class="kw">scale</span>(Boston[, <span class="op">-</span><span class="kw">ncol</span>(Boston)])</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">y =<span class="st"> </span>Boston[, <span class="kw">ncol</span>(Boston)]</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co"># random split of data in train and test</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"></a>
<a class="sourceLine" id="cb3-6" data-line-number="6">spl_train =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y), <span class="kw">round</span>(<span class="kw">length</span>(y) <span class="op">*</span><span class="st"> </span><span class="fl">0.75</span>))</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">spl_test =<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y), spl_train)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="kw">str</span>(spl_train)</a></code></pre></div>
<pre><code>##  int [1:380] 9 57 407 476 41 305 281 430 177 380 ...</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">str</span>(spl_test)</a></code></pre></div>
<pre><code>##  int [1:126] 2 3 12 13 14 23 27 28 36 38 ...</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co"># evaluation metric</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">mse =<span class="st"> </span><span class="cf">function</span> (y_true, y_pred) {</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">  </a>
<a class="sourceLine" id="cb7-5" data-line-number="5">  out =<span class="st"> </span><span class="kw">mean</span>((y_true <span class="op">-</span><span class="st"> </span>y_pred)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">  </a>
<a class="sourceLine" id="cb7-7" data-line-number="7">  out</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">}</a></code></pre></div>
<div id="the-kernelknn-function" class="section level2">
<h2>The KernelKnn function</h2>
<p>The KernelKnn function takes a number of arguments. To read details for each one of the arguments type ?KernelKnn::KernelKnn in the console.</p>
<p>A simple k-nearest-neighbors can be run with weights_function = NULL (the parameter ‘regression’ should be set to TRUE for regression),</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">library</span>(KernelKnn)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">preds_TEST =<span class="st"> </span><span class="kw">KernelKnn</span>(X[spl_train, ], <span class="dt">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="dt">k =</span> <span class="dv">5</span> , </a>
<a class="sourceLine" id="cb8-4" data-line-number="4">                       </a>
<a class="sourceLine" id="cb8-5" data-line-number="5">                       <span class="dt">method =</span> <span class="st">'euclidean'</span>, <span class="dt">weights_function =</span> <span class="ot">NULL</span>, <span class="dt">regression =</span> T)</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="kw">str</span>(preds_TEST)</a></code></pre></div>
<pre><code>##  num [1:126] 23.3 31.3 20.8 21.5 19.6 ...</code></pre>
<p><br> Using transf_categ_cols = TRUE, categorical features can be either encoded to dummy or to numeric features depending on the number of the unique values (here I convert the ‘chas’ and ‘rad’ features to factor to apply the <em>transf_categ_cols</em> parameter)</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">apply</span>(Boston, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">length</span>(<span class="kw">unique</span>(x)))</a></code></pre></div>
<pre><code>##    crim      zn   indus    chas     nox      rm     age     dis     rad 
##     504      26      76       2      81     446     356     412       9 
##     tax ptratio   black   lstat    medv 
##      66      46     357     455     229</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">tmp_bst =<span class="st"> </span>Boston</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">tmp_bst<span class="op">$</span>chas =<span class="st"> </span><span class="kw">as.factor</span>(tmp_bst<span class="op">$</span>chas)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3">tmp_bst<span class="op">$</span>rad =<span class="st"> </span><span class="kw">as.factor</span>(tmp_bst<span class="op">$</span>rad)</a>
<a class="sourceLine" id="cb12-4" data-line-number="4"></a>
<a class="sourceLine" id="cb12-5" data-line-number="5">preds_TEST =<span class="st"> </span><span class="kw">KernelKnn</span>(tmp_bst[spl_train, <span class="op">-</span><span class="kw">ncol</span>(tmp_bst)], </a>
<a class="sourceLine" id="cb12-6" data-line-number="6">                       </a>
<a class="sourceLine" id="cb12-7" data-line-number="7">                       <span class="dt">TEST_data =</span> tmp_bst[spl_test, <span class="op">-</span><span class="kw">ncol</span>(tmp_bst)], </a>
<a class="sourceLine" id="cb12-8" data-line-number="8">                       </a>
<a class="sourceLine" id="cb12-9" data-line-number="9">                       y[spl_train], <span class="dt">k =</span> <span class="dv">5</span> , <span class="dt">method =</span> <span class="st">'euclidean'</span>, </a>
<a class="sourceLine" id="cb12-10" data-line-number="10">                       </a>
<a class="sourceLine" id="cb12-11" data-line-number="11">                       <span class="dt">regression =</span> T, <span class="dt">transf_categ_cols =</span> T)</a>
<a class="sourceLine" id="cb12-12" data-line-number="12"><span class="kw">str</span>(preds_TEST)</a></code></pre></div>
<pre><code>##  num [1:126] 20.7 22.9 20.2 24 21 ...</code></pre>
<p><br> There are two ways to use a kernel in the KernelKnn function. The <strong>first option</strong> is to choose one of the existing kernels (<em>uniform</em>, <em>triangular</em>, <em>epanechnikov</em>, <em>biweight</em>, <em>triweight</em>, <em>tricube</em>, <em>gaussian</em>, <em>cosine</em>, <em>logistic</em>, <em>silverman</em>, <em>inverse</em>, <em>gaussianSimple</em>, <em>exponential</em>). Here, I use the <em>mahalanobis</em> metric (which takes advantage of the covariance matrix of the data, but it somewhat slows down training in comparison to the other distance metrics) and the <em>biweight</em> kernel, because they give optimal results (according to my <em>RandomSearchR</em> package),</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">preds_TEST_biw =<span class="st"> </span><span class="kw">KernelKnn</span>(X[spl_train, ], <span class="dt">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="dt">k =</span> <span class="dv">5</span>, </a>
<a class="sourceLine" id="cb14-2" data-line-number="2">                           </a>
<a class="sourceLine" id="cb14-3" data-line-number="3">                           <span class="dt">method =</span> <span class="st">'mahalanobis'</span>, <span class="dt">weights_function =</span> <span class="st">'biweight'</span>, </a>
<a class="sourceLine" id="cb14-4" data-line-number="4">                           </a>
<a class="sourceLine" id="cb14-5" data-line-number="5">                           <span class="dt">regression =</span> T, <span class="dt">transf_categ_cols =</span> F)</a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="kw">str</span>(preds_TEST_biw)</a></code></pre></div>
<pre><code>##  num [1:126] 22.7 35.1 22.1 20.8 19.3 ...</code></pre>
<p><br> The <strong>second option</strong> is to give a self defined kernel function. Here, I’ll pick the density function of the normal distribution with mean = 0.0 and standard deviation = 1.0 (the data are scaled to have mean zero and unit variance),</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">norm_kernel =<span class="st"> </span><span class="cf">function</span>(W) {</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb16-3" data-line-number="3">  W =<span class="st"> </span><span class="kw">dnorm</span>(W, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">1.0</span>)</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">  </a>
<a class="sourceLine" id="cb16-5" data-line-number="5">  W =<span class="st"> </span>W <span class="op">/</span><span class="st"> </span><span class="kw">rowSums</span>(W)</a>
<a class="sourceLine" id="cb16-6" data-line-number="6">  </a>
<a class="sourceLine" id="cb16-7" data-line-number="7">  <span class="kw">return</span>(W)</a>
<a class="sourceLine" id="cb16-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb16-9" data-line-number="9"></a>
<a class="sourceLine" id="cb16-10" data-line-number="10"></a>
<a class="sourceLine" id="cb16-11" data-line-number="11">preds_TEST_norm =<span class="st"> </span><span class="kw">KernelKnn</span>(X[spl_train, ], <span class="dt">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="dt">k =</span> <span class="dv">5</span>,</a>
<a class="sourceLine" id="cb16-12" data-line-number="12">                            </a>
<a class="sourceLine" id="cb16-13" data-line-number="13">                            <span class="dt">method =</span> <span class="st">'mahalanobis'</span>, <span class="dt">weights_function =</span> norm_kernel, </a>
<a class="sourceLine" id="cb16-14" data-line-number="14">                            </a>
<a class="sourceLine" id="cb16-15" data-line-number="15">                            <span class="dt">regression =</span> T, <span class="dt">transf_categ_cols =</span> F)</a>
<a class="sourceLine" id="cb16-16" data-line-number="16"><span class="kw">str</span>(preds_TEST_norm)</a></code></pre></div>
<pre><code>##  num [1:126] 23.6 31.1 22.3 22.1 20.3 ...</code></pre>
<p><br></p>
<p>The computations can be speed up by using the parameter <strong>threads</strong> (multiple cores can be run in parallel). There is also the option to exclude <strong>extrema</strong> (minimum and maximum distances) during the calculation of the k-nearest-neighbor distances using extrema = TRUE. The <em>bandwidth</em> of the existing kernels can be tuned using the <strong>h</strong> parameter. <br></p>
<p>K-nearest-neigbor calculations in the KernelKnn function can be accomplished using the following distance metrics : <em>euclidean</em>, <em>manhattan</em>, <em>chebyshev</em>, <em>canberra</em>, <em>braycurtis</em>, <em>minkowski</em> (by default the order ‘p’ of the minkowski parameter equals k), <em>hamming</em>, <em>mahalanobis</em>, <em>pearson_correlation</em>, <em>simple_matching_coefficient</em>, <em>jaccard_coefficient</em> and <em>Rao_coefficient</em>. The last four are similarity measures and are appropriate for binary data [0,1]. <br></p>
<p>I employed my RandomSearchR package to find the optimal parameters for the KernelKnn function and the following two pairs of parameters give an optimal mean-squared-error, <br> <br></p>
<table>
<thead>
<tr class="header">
<th align="right">k</th>
<th align="left">method</th>
<th align="left">kernel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">9</td>
<td align="left">mahalanobis</td>
<td align="left">triweight</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">canberra</td>
<td align="left">cosine</td>
</tr>
</tbody>
</table>
</div>
<div id="the-kernelknncv-function" class="section level2">
<h2>The KernelKnnCV function</h2>
<p>I’ll use the <em>KernelKnnCV</em> function to calculate the mean-squared-error using 3-fold cross-validation for the previous mentioned parameter pairs,</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">fit_cv_pair1 =<span class="st"> </span><span class="kw">KernelKnnCV</span>(X, y, <span class="dt">k =</span> <span class="dv">9</span>, <span class="dt">folds =</span> <span class="dv">3</span>, <span class="dt">method =</span> <span class="st">'mahalanobis'</span>, </a>
<a class="sourceLine" id="cb18-2" data-line-number="2">                           </a>
<a class="sourceLine" id="cb18-3" data-line-number="3">                           <span class="dt">weights_function =</span> <span class="st">'triweight'</span>, <span class="dt">regression =</span> T, </a>
<a class="sourceLine" id="cb18-4" data-line-number="4">                           </a>
<a class="sourceLine" id="cb18-5" data-line-number="5">                           <span class="dt">threads =</span> <span class="dv">5</span>, <span class="dt">seed_num =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="kw">str</span>(fit_cv_pair1)</a></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:168] 24.1 32.4 17.6 16.6 19.4 ...
##   ..$ : num [1:169] 30 21.8 21.5 20.5 22.6 ...
##   ..$ : num [1:169] 23.3 29.7 30.8 20.4 22.6 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:168] 2 5 8 9 14 23 24 29 34 35 ...
##   ..$ fold_2: int [1:169] 6 12 13 16 17 19 20 22 30 36 ...
##   ..$ fold_3: int [1:169] 1 3 4 7 10 11 15 18 21 25 ...</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">fit_cv_pair2 =<span class="st"> </span><span class="kw">KernelKnnCV</span>(X, y, <span class="dt">k =</span> <span class="dv">3</span>, <span class="dt">folds =</span> <span class="dv">3</span>, <span class="dt">method =</span> <span class="st">'canberra'</span>,</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">                           </a>
<a class="sourceLine" id="cb21-3" data-line-number="3">                           <span class="dt">weights_function =</span> <span class="st">'cosine'</span>, <span class="dt">regression =</span> T, </a>
<a class="sourceLine" id="cb21-4" data-line-number="4">                           </a>
<a class="sourceLine" id="cb21-5" data-line-number="5">                           <span class="dt">threads =</span> <span class="dv">5</span>, <span class="dt">seed_num =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">str</span>(fit_cv_pair2)</a></code></pre></div>
<p><br></p>
<p>Each cross-validated object returns a list of length 2 ( the first sublist includes the predictions for each fold whereas the second gives the indices of the folds)</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1">mse_pair1 =<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(fit_cv_pair1<span class="op">$</span>preds), </a>
<a class="sourceLine" id="cb23-2" data-line-number="2">                          </a>
<a class="sourceLine" id="cb23-3" data-line-number="3">                          <span class="cf">function</span>(x) <span class="kw">mse</span>(y[fit_cv_pair1<span class="op">$</span>folds[[x]]], </a>
<a class="sourceLine" id="cb23-4" data-line-number="4">                                          </a>
<a class="sourceLine" id="cb23-5" data-line-number="5">                                          fit_cv_pair1<span class="op">$</span>preds[[x]])))</a>
<a class="sourceLine" id="cb23-6" data-line-number="6">mse_pair1</a></code></pre></div>
<pre><code>## [1] 18.17392 18.29160 11.01078</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw">cat</span>(<span class="st">'mse for params_pair1 is :'</span>, <span class="kw">mean</span>(mse_pair1), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</a></code></pre></div>
<pre><code>## mse for params_pair1 is : 15.82543</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">mse_pair2 =<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(fit_cv_pair2<span class="op">$</span>preds), </a>
<a class="sourceLine" id="cb27-2" data-line-number="2">                          </a>
<a class="sourceLine" id="cb27-3" data-line-number="3">                          <span class="cf">function</span>(x) <span class="kw">mse</span>(y[fit_cv_pair2<span class="op">$</span>folds[[x]]], </a>
<a class="sourceLine" id="cb27-4" data-line-number="4">                                          </a>
<a class="sourceLine" id="cb27-5" data-line-number="5">                                          fit_cv_pair2<span class="op">$</span>preds[[x]])))</a>
<a class="sourceLine" id="cb27-6" data-line-number="6">mse_pair2</a></code></pre></div>
<pre><code>## [1] 26.84027 22.75759 18.53496</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">cat</span>(<span class="st">'mse for params_pair2 is :'</span>, <span class="kw">mean</span>(mse_pair2), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</a></code></pre></div>
<pre><code>## mse for params_pair2 is : 22.71094</code></pre>
<p><br></p>
</div>
<div id="adding-or-multiplying-kernels" class="section level2">
<h2>Adding or multiplying kernels</h2>
<p>In the KernelKnn package there is also the option to <strong>combine kernels</strong> (adding or multiplying) from the existing ones. For instance, if I want to multiply the <em>tricube</em> with the <em>gaussian</em> kernel, then I’ll give the following character string to the weights_function, <em>“tricube_gaussian_MULT”</em>. On the other hand, If I want to add the same kernels then the weights_function will be <em>“tricube_gaussian_ADD”</em>. I experimented with my RandomSearchR package combining the different kernels and the following two parameter settings gave optimal results,</p>
<p><br></p>
<table>
<thead>
<tr class="header">
<th align="right">k</th>
<th align="left">method</th>
<th align="left">kernel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">19</td>
<td align="left">mahalanobis</td>
<td align="left">triangular_triweight_MULT</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="left">mahalanobis</td>
<td align="left">biweight_triweight_gaussian_MULT</td>
</tr>
</tbody>
</table>
<p><br></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">fit_cv_pair1 =<span class="st"> </span><span class="kw">KernelKnnCV</span>(X, y, <span class="dt">k =</span> <span class="dv">19</span>, <span class="dt">folds =</span> <span class="dv">3</span>, <span class="dt">method =</span> <span class="st">'mahalanobis'</span>, </a>
<a class="sourceLine" id="cb31-2" data-line-number="2">                           </a>
<a class="sourceLine" id="cb31-3" data-line-number="3">                           <span class="dt">weights_function =</span> <span class="st">'triangular_triweight_MULT'</span>, </a>
<a class="sourceLine" id="cb31-4" data-line-number="4">                           </a>
<a class="sourceLine" id="cb31-5" data-line-number="5">                           <span class="dt">regression =</span> T, <span class="dt">threads =</span> <span class="dv">5</span>, <span class="dt">seed_num =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">str</span>(fit_cv_pair1)</a></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:168] 24.3 32.4 17.8 17.1 19.5 ...
##   ..$ : num [1:169] 28.6 21.5 21.9 20.4 22.2 ...
##   ..$ : num [1:169] 23.2 27.6 31.1 20.7 22.4 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:168] 2 5 8 9 14 23 24 29 34 35 ...
##   ..$ fold_2: int [1:169] 6 12 13 16 17 19 20 22 30 36 ...
##   ..$ fold_3: int [1:169] 1 3 4 7 10 11 15 18 21 25 ...</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">fit_cv_pair2 =<span class="st"> </span><span class="kw">KernelKnnCV</span>(X, y, <span class="dt">k =</span> <span class="dv">18</span>, <span class="dt">folds =</span> <span class="dv">3</span>, <span class="dt">method =</span> <span class="st">'mahalanobis'</span>, </a>
<a class="sourceLine" id="cb34-2" data-line-number="2">                           </a>
<a class="sourceLine" id="cb34-3" data-line-number="3">                           <span class="dt">weights_function =</span> <span class="st">'biweight_triweight_gaussian_MULT'</span>, </a>
<a class="sourceLine" id="cb34-4" data-line-number="4">                           </a>
<a class="sourceLine" id="cb34-5" data-line-number="5">                           <span class="dt">regression =</span> T, <span class="dt">threads =</span> <span class="dv">5</span>, <span class="dt">seed_num =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="kw">str</span>(fit_cv_pair2)</a></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:168] 24.2 32.5 17.8 17.1 19.4 ...
##   ..$ : num [1:169] 28.9 21.7 21.8 20.4 22.1 ...
##   ..$ : num [1:169] 23.3 27.7 31.2 20.6 22.4 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:168] 2 5 8 9 14 23 24 29 34 35 ...
##   ..$ fold_2: int [1:169] 6 12 13 16 17 19 20 22 30 36 ...
##   ..$ fold_3: int [1:169] 1 3 4 7 10 11 15 18 21 25 ...</code></pre>
<p><br></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">mse_pair1 =<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(fit_cv_pair1<span class="op">$</span>preds), </a>
<a class="sourceLine" id="cb37-2" data-line-number="2">                          </a>
<a class="sourceLine" id="cb37-3" data-line-number="3">                          <span class="cf">function</span>(x) <span class="kw">mse</span>(y[fit_cv_pair1<span class="op">$</span>folds[[x]]], </a>
<a class="sourceLine" id="cb37-4" data-line-number="4">                                          </a>
<a class="sourceLine" id="cb37-5" data-line-number="5">                                          fit_cv_pair1<span class="op">$</span>preds[[x]])))</a>
<a class="sourceLine" id="cb37-6" data-line-number="6">mse_pair1</a></code></pre></div>
<pre><code>## [1] 18.73885 18.64990 11.21641</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="kw">cat</span>(<span class="st">'mse for params_pair1 is :'</span>, <span class="kw">mean</span>(mse_pair1), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</a></code></pre></div>
<pre><code>## mse for params_pair1 is : 16.20172</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1">mse_pair2 =<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(fit_cv_pair2<span class="op">$</span>preds), </a>
<a class="sourceLine" id="cb41-2" data-line-number="2">                          </a>
<a class="sourceLine" id="cb41-3" data-line-number="3">                          <span class="cf">function</span>(x) <span class="kw">mse</span>(y[fit_cv_pair2<span class="op">$</span>folds[[x]]], </a>
<a class="sourceLine" id="cb41-4" data-line-number="4">                                          </a>
<a class="sourceLine" id="cb41-5" data-line-number="5">                                          fit_cv_pair2<span class="op">$</span>preds[[x]])))</a>
<a class="sourceLine" id="cb41-6" data-line-number="6">mse_pair2</a></code></pre></div>
<pre><code>## [1] 19.12602 18.63044 11.21680</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">cat</span>(<span class="st">'mse for params_pair2 is :'</span>, <span class="kw">mean</span>(mse_pair2), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</a></code></pre></div>
<pre><code>## mse for params_pair2 is : 16.32442</code></pre>
<p><br></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
