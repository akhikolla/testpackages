@article{hoerl1970,
   author = {A. E. Hoerl and W. Kennard},
   title  = {{R}idge {R}egression: {B}iased {E}stimation for {N}onorthogonal {P}roblems},
   journal = {Technometrics},
   year   = {1970},
   volume = {12},
   pages  = {55--67}
}
@article{akaike1974,
    author = {H. Akaike},
    journal = {{Automatic Control, IEEE Transactions on}},
    number = {6},
    pages = {716--723},
    title = {{A new look at the statistical model identification}},
    volume = {19},
    year = {1974}
}

@article{dempster1977,
  author = {A. P. Dempster and M. N. Laird and D. B. Rubin},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  pages = {1--22},
  title = {Maximum {L}ikelihood from {I}ncomplete {D}ata via the {EM} {A}lgorithm},
  volume = 39,
  year = 1977
}

@article{schwarz1978,
   author = {G. Schwarz},
   title  = {{E}stimating the {D}imension of a {M}odel},
   journal = {Annals of Statistics},
   year   = {1978},
   volume = {6},
   pages  = {461--464}
}
@incollection{policello1981,
 year={1981},
 isbn={978-94-009-8554-4},
 booktitle={Statistical Distributions in Scientific Work},
 volume={79},
 series={NATO Advanced study Institutes Series},
 doi={10.1007/978-94-009-8552-0_9},
 title={Conditional {M}aximum {L}ikelihood {E}stimation in {G}aussian Mixtures},
 publisher={Springer Netherlands},
 keywords={Gaussian mixtures; maximum likelihood estimation; mixtures of distributions; normal mixtures},
 author={Policello G.},
 pages={111-125},
 language={English}
}
@article{stein1981,
   author = {Stein C.},
   title  = {Estimation of the {M}ean of a {M}ultivariate {N}ormal {D}istribution},
   journal = {Annals of Statististics},
   year   = {1981},
   volume = {9},
   pages = {1135--1151}
}
@article{joliffe82,
    abstract = {{The use of principal components in regression has received a lot of attention in the literature in the past few years, and the topic is now beginning to appear in textbooks. Along with the use of principal component regression there appears to have been a growth in the misconception that the principal components with small eigenvalues will very rarely be of any use in regression. The purpose of this note is to demonstrate that these components can be as important as those with large variance. This is illustrated with four examples, three of which have already appeared in the literature.}},
    author = {I. T. Jolliffe},
    journal = {Applied Statistics},
    number = {3},
    pages = {300+},
    title = {{A Note on the Use of Principal Components in Regression}},
    volume = {31},
    year = {1982}
}

@article{casella1985,
    author = {G. Casella},
    journal = {The American Statistician},
    keywords = {empirical-bayes},
    number = {2},
    pages = {83--87},
    title = {{An {I}ntroduction to {E}mpirical {B}ayes {D}ata {A}nalysis}},
    volume = {39},
    year = {1985}
}
@article{beauchamp1988,
   author = {Mitchell T.J. and Beauchamp J.J.},
   title  = {{B}ayesian {V}ariable {S}election in {L}inear {R}egression},
   journal = {Journal of the American Statistical Association},
   year   = {1988},
   volume = {83},
   issue = {404},
   pages = {1023--1032}
}
@article{wei1990,
  author  = {C. G. Wei and M.A. Tanner},
  journal = {Journal of the American Statistical Association},
  pages   = {699--704},
  title   = {A {M}onte {C}arlo {I}mplementation of the {EM} {A}lgorithm and the {P}oor {M}an's {D}ata {A}ugmentation {A}lgorithms},
  volume  = {85},
  year    = 1990
}
@book{searle1992variance,
  title={Variance components},
  author={S.R. Searle and G. Casella and C.E. McCulloch},
  series={Wiley series in probability and mathematical statistics: Applied probability and statistics},
  year={1992},
  publisher={Wiley}
}

%% inria-00074164, version 1
%% http://hal.inria.fr/inria-00074164
@article{celeux:inria-00074164,
    author = {G. Celeux and D. Chauveau and J. Diebolt},
    title = {{S}ome {S}tochastic versions of the {EM} {A}lgorithm},
    journal = {Journal of Statistical Computation and Simulation},
    year = {1996},
    volume = {55},
    pages = {287--314}
}

@article{tibshirani1996,
    author = {R. Tibshirani},
    title = {Regression {S}hrinkage and {S}election {V}ia the {L}asso},
    journal = {Journal of the Royal Statistical Society, Series B},
    year = {1996},
    volume = {58},
    pages = {267--288}
}
@article{Booth1999,
    author = {Booth J. G. and Hobert J. P.},
    citeulike-article-id = {756577},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2680750},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2680750},
    doi = {10.2307/2680750},
    journal = {Journal of the Royal Statistical Society. Series B (Methodology)},
    keywords = {emalgorithm},
    number = {1},
    pages = {265--285},
    posted-at = {2009-05-02 19:31:36},
    priority = {2},
    title = {{Maximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm}},
    url = {http://dx.doi.org/10.2307/2680750},
    volume = {61},
    year = {1999}
}
@article{biernacki2000,
 author = {C. Biernacki and G. Celeux and G. Goavert},
 journal = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}},
 title = {{Assessing a Mixture Model for Clustering with the Integrated Completed Likelihood}},
 volume = {22},
 number = {7},
 pages = {719--725},
 year = {2000}
}
@article{levine2001,
    author = {R. A. Levine and G. Casella},
    journal = {Journal of Computational and Graphical Statistics},
    keywords = {emalgorithm},
    number = {3},
    pages = {422--439},
    title = {{Implementations of the Monte Carlo EM Algorithm}},
    volume = {10},
    year = {2001}
}
@book{Hast:Tibs:Frie:2001,
  AUTHOR = {Hastie T. and Tibshirani R. and Friedman J. H.},
  TITLE = {The elements of statistical learning: data mining, inference, and prediction: with 200 full-color illustrations},
  YEAR = {2001},
  PAGES = {533},
  PUBLISHER = {New York: Springer-Verlag}
}
@article{efron2004,
    author = {B. Efron and T. Hastie and I. Johnstone and R. Tibshirani},
    title = {Least angle regression},
    journal = {Annals of Statistics},
    year = {2004},
    volume = {32},
    pages = {407--499}
}
@article{ishwaran2005,
    author = {H. Ishwaran and J. Sunil Rao},
    title = {Spike and slab variable selection: frequentist and {B}ayesian strategies},
    journal = {Annals of Statistics},
    year = {2005},
    volume = {33},
    number = {2},
    pages = {730--773}
}
@article{zou2005,
    author = {H. Zou and T. Hastie},
    title = {Regularization and variable selection via the Elastic Net},
    journal = {Journal of the Royal Statistical Society, Series B},
    year = {2005},
    volume = {67},
    pages = {301--320}
}
@article{caffo2005,
title = {Ascent-based {M}onte {C}arlo {E}xpectation-{M}aximization},
author = {Caffo B. S. and Jank W. and Jones G. L.},
year = {2005},
journal = {Journal of the Royal Statistical Society Series B},
volume = {67},
number = {2},
pages = {235-251},
abstract = { The expectation-maximization (EM) algorithm is a popular tool for maximizing likelihood functions in the presence of missing data. Unfortunately, EM often requires the evaluation of analytically intractable and high dimensional integrals. The Monte Carlo EM (MCEM) algorithm is the natural extension of EM that employs Monte Carlo methods to estimate the relevant integrals. Typically, a very large Monte Carlo sample size is required to estimate these integrals within an acceptable tolerance when the algorithm is near convergence. Even if this sample size were known at the onset of implementation of MCEM, its use throughout all iterations is wasteful, especially when accurate starting values are not available. We propose a data-driven strategy for controlling Monte Carlo resources in MCEM. The algorithm proposed improves on similar existing methods by recovering EM's ascent (i.e. likelihood increasing) property with high probability, being more robust to the effect of user-defined inputs and handling classical Monte Carlo and Markov chain Monte Carlo methods within a common framework. Because of the first of these properties we refer to the algorithm as 'ascent-based MCEM'. We apply ascent-based MCEM to a variety of examples, including one where it is used to accelerate the convergence of deterministic EM dramatically. Copyright 2005 Royal Statistical Society.},
url = {http://EconPapers.repec.org/RePEc:bla:jorssb:v:67:y:2005:i:2:p:235-251}
}
@article{Gunawardana05convergencetheorems,
    title = {{Convergence theorems for generalized alternating minimization procedures}},
    author = {A. Gunawardana and W. Byrne},
    journal = {Journal of Machine Learning Research},
    year = {2005},
    volume = {6},
    pages = {2049--2073}
}
@article{scheetz2006regulation,
    author = {T.E. Scheetz},
    journal = {Proceedings of the National Academy of Sciences},
    number = {39},
    pages = {14429},
    title = {{Regulation of gene expression in the mammalian eye and its relevance to eye disease}},
    volume = {103},
    year = {2006}
}

@article{zou2007,
    author = {Zou H. and Hastie T. and Tibshirani R.},
    issn = {0090-5364},
    journal = {Annals of Statistics},
    keywords = {aic, cp, lasso, statistics},
    month = oct,
    number = {5},
    pages = {2173--2192},
    title = {{On the degrees of freedom of the lasso}},
    url = {http://dx.doi.org/10.1214/009053607000000127},
    volume = {35},
    year = {2007}
}
@article{park2007,
    author = {M. Y. Park and T. Hastie and R. Tibshirani},
    title = {Averaged gene expressions for regression},
    journal = {Biostatistics},
    year = {2007},
    volume = {8},
    issue = {2},
    pages = {212--227}
}
@article{biernacki2007,
    author = {Biernacki C.},
    title = {Degeneracy in the {M}aximum {L}ikelihood {E}stimation of {U}nivariate {G}aussian {M}ixtures for {G}rouped {D}ata and {B}ehaviour of the {EM} {A}lgorithm},
    journal = {Journal of Scandinavian Statistics},
    year = {2007},
    volume = {34},
    pages = {569--586}
}
@article{bondell2008,
    author = {H. D. Bondell and B. J. Reich},
    title = {Simultaneous {R}egression {S}hrinkage, {V}ariable {S}election, and {S}upervised {C}lustering of {P}redictors with {OSCAR}},
    journal = {Biometrics},
    year = {2008},
    volume = {64},
    pages  = {115--123}
}
@book{she2008,
  title={Sparse {R}egression with {E}xact {C}lustering},
  author={She Y. and Stanford University},
  isbn={9780549849957},
  year={2008},
  publisher={Stanford University}
}
@article{govaert2008,
    author = {G. Govaert and M. Nadif},
    title = {{Block clustering with Bernoulli mixture models: Comparison of different approaches}},
    journal = {Computational Statistics and Data analysis},
    year = {2008},
    volume = {52},
    pages  = {3233--3245}
}
@book{ggplot2-ref,
    author = {H. Wickham},
    title = {\pkg{ggplot2}: elegant graphics for data analysis},
    publisher = {Springer New York},
    year = {2009},
    url = {http://had.co.nz/ggplot2/book},
  }
@article{daye2009,
  author={Daye Z. J. and Jeng X. J.},
  title={Shrinkage and model selection with correlated variables via weighted fusion},
  journal={Computational Statistics \& Data Analysis},
  year=2009,
  volume={53},
  number={4},
  pages={1284-1298},
  month={February},
  keywords={},
  abstract={In this paper, we propose the weighted fusion, a new penalized regression and variable selection method for data with correlated variables. The weighted fusion can potentially incorporate information redundancy among correlated variables for estimation and variable selection. Weighted fusion is also useful when the number of predictors p is larger than the number of observations n. It allows the selection of more than n variables in a motivated way. Real data and simulation examples show that weighted fusion can improve variable selection and prediction accuracy.},
  url={http://ideas.repec.org/a/eee/csdana/v53y2009i4p1284-1298.html}
}
@article{petry2009,
    author = {Petry S. and Tutz G.},
    title = {Shrinkage and variable selection by polytopes},
    journal = {Technical report No. 053, Department of Statistics, University of Munich},
    year = {2009}
}
@article{chun2009,
    author = {Chun H. and Keles S.},
    title = {Expression {Q}uantitative {T}rait {L}oci {M}apping {W}ith {M}ultivariate {S}parse {P}artial {L}east {S}quares {R}egression},
    journal = {Genetics},
    year = {2009},
    volume = {182},
    issn   = {1},
    pages  = {79--90}
}
@article{shen2010,
    author  = {Shen X. and Huang H.},
    title   = {Grouping pursuit in regression},
    journal = {Journal of American Statistical Association},
    year    = {2010},
    volume  = {105},
    pages   = {727--739}
}
@article{glmnet-ref,
    title = {{Regularization Paths for Generalized Linear Models via Coordinate Descent}},
    author = {J. Friedman and T. Hastie and R. Tibshirani},
    journal = {Journal of Statistical Software},
    year = {2010},
    volume = {33},
    number = {1},
    pages = {1--22},
    url = {http://www.jstatsoft.org/v33/i01/},
  }

@article{mariadassou2010,
    author  = {M. Mariadassou and S. Robin and C. Vacher},
    title   = {{Uncovering Latent Structure in Valued Graphs: a Variational Approach}},
    journal = {The Annals of Applied Statistics},
    year    = {2010},
    volume  = {4},
    number  = {2},
    pages   = {715--742}
}
@article{Rcpp-ref,
    title = {\pkg{Rcpp}: {Seamless {R} and {C++} Integration}},
    author = {D. Eddelbuettel and R. Fran\c{c}ois},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {40},
    number = {8},
    pages = {1--18},
    url = {http://www.jstatsoft.org/v40/i08/},
}
@article{petrone2012,
    author = {S. Petrone and J. Rousseau and C. Scricciolo},
    title = {{B}ayes and empirical {B}ayes: do they merge?},
    journal = {{arXiv:1204.1470v1}},
    year = {2012}
}
@manual{spikeslab-ref,
    title = {\pkg{spikeslab} : {Prediction and variable selection using spike and slab regression}},
    author = {H. Ishwaran and J.S. Rao and U.B. Kogalur},
    publisher = {manual},
    year = {2013},
    note = {R package version 1.1.5},
    url = {http://cran.r-project.org/web/packages/spikeslab/},
    pdf = {http://cran.r-project.org/web/packages/spikeslab/spikeslab.pdf},
}
@article{RcppEigen-ref,
  author =	"D. Bates and D. Eddelbuettel",
  title =	"Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package",
  journal =	"Journal of Statistical Software",
  volume =	"52",
  number =	"5",
  pages =	"1--24",
  year = 	"2013",
  URL =  	"http://www.jstatsoft.org/v52/i05",
}


@article{biernacki2013,
 author = {C. Biernacki and J. Jacques},
 title = {{A generative model for rank data based on insertion sort algorithm}},
 journal = {Computational Statistics and Data Analysis},
 volume = {58},
 pages = {162--176},
 year = {2013}
}
@article{pacs2013,
    author = {D. B. Sharma and H. D. Bondell and H. H. Zhang},
    title = {Consistent {G}roup {I}dentification and {V}ariable {S}election in {R}egression with {C}orrelated {P}redictors},
    journal = {Journal of Computational and Graphical Statistics.},
    year = {2013},
    volume = {22},
    number = {2},
    pages  = {319-340}
}
@article{yengo2013,
    author = {L. Yengo and J. Jacques and C. Biernacki},
    title = {{Variable clustering in high dimensional linear regression models}},
    journal = {Journal de la Société Française de Statistique. In Press.},
    year = {2014},
    volume = {155},
    number = {2},
    pages  = {38-56}
}

@PhDThesis{Yengo2014,
title = {Classification et sélection de variables en régression : application à l'étiologie génétique des maladies métaboliques},
author = {L. Yengo},
school = {University Lille 1},
year = {2014}}

