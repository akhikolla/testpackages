% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nnf-loss.R
\name{nnf_binary_cross_entropy_with_logits}
\alias{nnf_binary_cross_entropy_with_logits}
\title{Binary_cross_entropy_with_logits}
\usage{
nnf_binary_cross_entropy_with_logits(
  input,
  target,
  weight = NULL,
  reduction = c("mean", "sum", "none"),
  pos_weight = NULL
)
}
\arguments{
\item{input}{Tensor of arbitrary shape}

\item{target}{Tensor of the same shape as input}

\item{weight}{(Tensor, optional) a manual rescaling weight if provided it's
repeated to match input tensor shape.}

\item{reduction}{(string, optional) â€“ Specifies the reduction to apply to the
output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean':
the sum of the output will be divided by the number of elements in the output,
'sum': the output will be summed. Default: 'mean'}

\item{pos_weight}{(Tensor, optional) a weight of positive examples.
Must be a vector with length equal to the number of classes.}
}
\description{
Function that measures Binary Cross Entropy between target and output
logits.
}
