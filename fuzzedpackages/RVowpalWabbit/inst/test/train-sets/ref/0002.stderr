final_regressor = models/0002.model
using no cache
Reading from train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
learning_rate set to 10
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.110447   0.110447          3      3.0     0.5498   0.3591       15
0.070578   0.030710          6      6.0     0.2681   0.0000       15
0.064146   0.056427         11     11.0     0.4315   0.0000       15
0.039332   0.014519         22     22.0     0.5519   0.5562       15
0.021432   0.003532         44     44.0     0.5514   0.6163       15
0.013416   0.005214         87     87.0     0.5140   0.5052       15
0.008898   0.004379        174    174.0     0.5596   0.5639       15
0.006059   0.003221        348    348.0     0.5475   0.5427       15
0.004075   0.002091        696    696.0     0.3421   0.4014       15
0.002947   0.001819       1392   1392.0     0.4996   0.4716       15
0.002098   0.001249       2784   2784.0     0.5090   0.5203       15
0.001704   0.001310       5568   5568.0     0.6413   0.5771       15
0.001770   0.001835      11135  11135.0     0.3869   0.4407       15
0.002000   0.002231      22269  22269.0     0.5063   0.5228       15
0.002340   0.002680      44537  44537.0     0.4905   0.4860       15

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.002412
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1121190
